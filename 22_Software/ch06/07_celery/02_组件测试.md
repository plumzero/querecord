
这里会对两种 Broker-Backend 模式进行测试。

在测试之前，请确认 redis 和 postgresql 服务已经安装并可以顺利访问。

### redis+redis 模式

redis 既作为 Broker，也作为 Backend。

这里将 `/home/celery/test` 作为测试目录，当然也可以选择其他的。建议仍使用 celery 用户作为操作用户。

现在，将下面的代码文件 `tasks.py` 放到 `/home/celery/test` 目录下:
```py
    # -*- coding: utf-8 -*-

    import time
    from celery import Celery

    broker = 'redis://:redispassword@192.168.2.102:6379/0'
    backend = 'redis://:redispassword@192.168.2.102:6379/1'

    app = Celery('my_task', broker=broker, backend=backend)

    @app.task
    def add(x, y):
        time.sleep(5)   # 模拟耗时操作
        return x + y
```
这段代码做了如下几件事:
* 创建了一个 Celery 实例 app，名称为 `my_task`
* 指定消息中间件，即 Broker 为 redis，选择 0 号数据库
* 指定后端存储 redis，即 Backend 为 redis，选择 1 号数据库
* 创建了一个 Celery 任务 `add`，当函数被 `@app.task` 修饰后，就成为可被 Celery 调度的任务

在 celery shell 会话中执行如下命令:
```sh
    celery$ celery -A tasks worker --loglevel=info
```
还是有必要对参数的顺序与意义进行说明的:
* `-A` 是归属于 celery 命令的参数(可以通过 `celery --help` 查看)，表示 app，后面紧跟 app 的名称，这里是 tasks，你也可以写成 `-A tasks.app`
* `worker` 是 celery 命令的子命令，表示启动一个任务处理单元。
可以看出，参数与命令的书写还是有顺序的，否则会无法正确的解析参数，报错。

执行命令顺利的话，会在当前 shell 会话中进行如下类似打印:
```sh
    -------------- celery@ubuntu v5.1.2 (sun-harmonics)
    --- ***** ----- 
    -- ******* ---- Linux-4.4.0-186-generic-x86_64-with-glibc2.10 2021-09-02 00:42:45
    - *** --- * --- 
    - ** ---------- [config]
    - ** ---------- .> app:         my_task:0x7f3e6460f4c0
    - ** ---------- .> transport:   redis://:**@192.168.2.102:6379/0
    - ** ---------- .> results:     redis://:**@192.168.2.102:6379/1
    - *** --- * --- .> concurrency: 4 (prefork)
    -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
    --- ***** ----- 
    -------------- [queues]
                    .> celery           exchange=celery(direct) key=celery
                    

    [tasks]
    . tasks.add

    [2021-09-02 00:42:45,905: INFO/MainProcess] Connected to redis://:**@192.168.2.102:6379/0
    [2021-09-02 00:42:45,917: INFO/MainProcess] mingle: searching for neighbors
    [2021-09-02 00:42:46,947: INFO/MainProcess] mingle: all alone
    [2021-09-02 00:42:46,979: INFO/MainProcess] celery@ubuntu ready.
```
说明已经准备好(ready)了。

去 0 号数据库查看，会创建三个集合，如下:
```sh
    127.0.0.1:6379> keys *
    1) "_kombu.binding.celery"
    2) "_kombu.binding.celery.pidbox"
    3) "_kombu.binding.celeryev"
```
暂时先不用管它。

再打开一个 celery 用户 shell 会话，进入 `/home/celery/test` 目录下(要进行相对路径下的包引入)，依次进行如下操作:
```sh
    celery$ python3
    >>> from tasks import add
    >>> add.delay(2,8)
    <AsyncResult: 75418f8a-c23a-4ce1-b61e-9633af7babe3>
```
可以看到会产生一个 AsyncResult，从名称上看是一个标记异步结果的 uuid 。

同时，启动 worker 的 shell 会话追加打印出如下内容:
```sh
    [2021-09-02 00:44:03,336: INFO/MainProcess] Task tasks.add[75418f8a-c23a-4ce1-b61e-9633af7babe3] received
    [2021-09-02 00:44:08,362: INFO/ForkPoolWorker-1] Task tasks.add[75418f8a-c23a-4ce1-b61e-9633af7babe3] succeeded in 5.024489921000168s: 10
```
看起来是计算成功了。

这个时候去 1 号数据库查看:
```sh
    127.0.0.1:6379[1]> keys *
    1) "celery-task-meta-75418f8a-c23a-4ce1-b61e-9633af7babe3"
    127.0.0.1:6379[1]> type celery-task-meta-75418f8a-c23a-4ce1-b61e-9633af7babe3
    string
    127.0.0.1:6379[1]> get celery-task-meta-75418f8a-c23a-4ce1-b61e-9633af7babe3
    "{\"status\": \"SUCCESS\", \"result\": 10, \"traceback\": null, \"children\": [], \"date_done\": \"2021-09-02T07:44:08.346607\", \"task_id\": \"75418f8a-c23a-4ce1-b61e-9633af7babe3\"}"
```
看起来计算结果也保存成功了。

### redis+postgresql 模式

将上述测试环境清理(清空 redis 并对测试目录下的生成文件进行清理)。

仍然使用同样的 `tasks.py` 脚本，不过这里使用 PostgreSQL 作为存储后端，所以原脚本需要进行如下修改:
```py
    backend = 'db+postgresql+psycopg2://pguser:@192.168.2.113/celery'
```
这里使用 pguser 角色进行无认证登录，同时确保要访问的数据库中已经存在 celery 库，可以通过如下 SQL 命令创建:
```sql
    postgres=# CREATE DATABASE celery;
```

按照同样的方式去执行，我这里看到的打印(关键信息)如下:
```sh
    [2021-09-02 01:18:00,254: INFO/MainProcess] Task tasks.add[42aa3e94-7abe-4bac-a4cc-f989af945eb4] received
    [2021-09-02 01:18:06,254: INFO/ForkPoolWorker-1] Task tasks.add[42aa3e94-7abe-4bac-a4cc-f989af945eb4] succeeded in 5.997454688000289s: 20
```

现在去 PostgreSQL 中查看 celery 库(以 pguser 登录查看):
```sh
    postgres$ psql -h 192.168.2.113 -p 5432 celery pguser
    celery=> \dt
                List of relations
    Schema |        Name        | Type  | Owner  
    --------+--------------------+-------+--------
    public | celery_taskmeta    | table | pguser
    public | celery_tasksetmeta | table | pguser
    (2 rows)
```
可以看到创建了两个表，其中 `celery_tasksetmeta` 表是空的。现在查看另外一个表:
```sh
    celery=> select * from celery_taskmeta;
    id |               task_id                | status  |    result    |         date_done          | traceback | name | args | kwargs | worker | retries | queue 
    ----+--------------------------------------+---------+--------------+----------------------------+-----------+------+------+--------+--------+---------+-------
    1 | 42aa3e94-7abe-4bac-a4cc-f989af945eb4 | SUCCESS | \x80054b142e | 2021-09-02 08:18:06.222895 |           |      |      |        |        |         | 
```
`result` 是一串 bytea 类型的字节串，psycopg2 对原始数据进行了编码保存为这样的结果。


至此，组件测试完毕。

因为使用 postgresql 存储的结果是二进制编码，后面的测试使用 redis 作为后端存储。
