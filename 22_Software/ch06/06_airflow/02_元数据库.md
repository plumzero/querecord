
参考
* [入口点脚本](https://github.com/apache/airflow/blob/89bef9199c1b96c4f02501ec4e5f309414a55ac9/scripts/in_container/prod/entrypoint_prod.sh)
* [Set up a Database Backend](https://airflow.apache.org/docs/apache-airflow/stable/howto/set-up-database.html)

airflow 默认使用 SQLite 作为元数据库，不过在节点迁移方面很不方便，只用作测试。

这里选择 PostgreSQL 作为元数据库(metastore)，airflow 通过 `SqlAlchemy` 与元数据库实现连接。

### PostgreSQL 配置

登录到 PostgreSQL 数据库中，创建数据库与角色:
```sh
    root# su - postgres
    postgres$ psql -h 192.168.2.113 -p 5432 postgres postgres
```

进入 PostgreSQL 会话环境，创建数据库(名称随意)，这里使用 `airflow`:
```sh
    postgres=# CREATE DATABASE airflow;
    CREATE DATABASE
```

创建角色(名称随意)，这里是 `airflower`，同时为了安全为该角色设置密码。之后将上面创建的数据库赋权给 airflower 用户:
```sh
    postgres=# CREATE USER airflower WITH PASSWORD 'yourpassword';
    CREATE ROLE
    postgres=# GRANT ALL PRIVILEGES ON DATABASE airflow TO airflower;
    GRANT
```

之后更新 PostgreSQL 配置 `pg_hba.conf`，设置 airflower 用户对 airflow 数据库的访问方式:
```conf
    host    all             airflower       192.168.0.0/16          password
```
配置好之后重新 reload 数据库，使修改生效。

现在修改配置 `airflow.cfg`，以使 airflow 与 PostgreSQL 能够建立联系。其连接语法如下:
```cfg
    postgresql+psycopg2://<user>:<password>@<host>/<db>
```
如果角色对数据库的访问为可信任(trust)，那么 password 可省略。数据库访问端口也可省略，对于 PostgreSQL，默认为 5432 。

psycopg2 是 airflow 用于与 PostgreSQL 建立联系所使用的驱动，更多关于它的信息参见[这里](https://docs.sqlalchemy.org/en/13/dialects/postgresql.html)。

这里将配置修改为:
```cfg
    [core]
    sql_alchemy_conn = postgresql+psycopg2://airflower:yourpassword@192.168.2.113:5432/airflow
```

最后，初始化数据库:
```sh
    airflow$ airflow db init
```

> 每当你对元数据库或后端存储进行修改时(如可能会改变某些权限)，可以使用命令 `airflow db upgrade`，而不
> 是 `airflow db init`，因为后者会创建大量的默认连接、图表等，而这些在生产环境中是不需要的。

### 创建 Web 角色

需要创建一些角色，比如管理员、普通用户之类的，等等。不过角色的创建不是随意的，具体可以创建哪些需要看这里:

进入数据库 airflow 中，里面有个表 `ab_role`，查看:
```sh
    airflow=> select * from ab_role;
    id |  name  
    ----+--------
    1 | Admin
    2 | Public
    3 | Viewer
    4 | User
    5 | Op
    (5 rows)
```
是的，只能从这里面选择。这里创建一个 `Admin` 角色和一个 `Viewer` 角色:
```sh
    airflow$ airflow users create --username libei --firstname li --lastname bei --email libei@email.com --role Admin --password admin123
    Admin user libei created

    airflow$ airflow users create --username 郭靖 --firstname 郭 --lastname 靖 --email song@email.com --role Viewer --password viewer123
    Viewer user 郭靖 created
```

再进入 airflow 数据库，查看 `ab_user` 和 `ab_user_role`:
```sh
    airflow=> select id, first_name, last_name, username, changed_on, active, email, created_on from ab_user;
    id | first_name | last_name | username |         changed_on         | active |      email      |         created_on         
    ----+------------+-----------+----------+----------------------------+--------+-----------------+----------------------------
    1 | li         | bei       | libei    | 2021-08-31 22:43:21.98106  | t      | libei@email.com | 2021-08-31 22:43:21.981051
    2 | 郭         | 靖        | 郭靖     | 2021-08-31 22:52:36.196941 | t      | song@email.com  | 2021-08-31 22:52:36.196932
    (2 rows)

    airflow=> select * from ab_user_role;
    id | user_id | role_id 
    ----+---------+---------
    1 |       1 |       1
    2 |       2 |       3
    (2 rows)
```

好了，现在可以启动 webserver 了:
```sh
    airflow$ airflow webserver -p 8080
    ____________       _____________
    ____    |__( )_________  __/__  /________      __
    ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
    ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
    _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
    [2021-09-06 15:12:37,294] {dagbag.py:496} INFO - Filling up the DagBag from /dev/null
    Running the Gunicorn Server with:
    Workers: 4 sync
    Host: 0.0.0.0:8080
    Timeout: 120
    Logfiles: - -
    Access Logformat: 
    =================================================================            
    [2021-09-06 15:12:41 +0800] [15109] [INFO] Starting gunicorn 20.1.0
    [2021-09-06 15:12:41 +0800] [15109] [INFO] Listening at: http://0.0.0.0:8080 (15109)
    [2021-09-06 15:12:41 +0800] [15109] [INFO] Using worker: sync
    [2021-09-06 15:12:41 +0800] [15111] [INFO] Booting worker with pid: 15111
    [2021-09-06 15:12:41 +0800] [15112] [INFO] Booting worker with pid: 15112
    [2021-09-06 15:12:42 +0800] [15113] [INFO] Booting worker with pid: 15113
    [2021-09-06 15:12:42 +0800] [15114] [INFO] Booting worker with pid: 15114
```
如果需要在后台启动，可以加上参数 `-D`。

在浏览器地址栏中输入如下 url 访问(192.168.3.40 是 airflow 部署机器地址):
```sh
    http://192.168.3.40:8080
```

顺利的话，输入用户名和密码就可以访问了。
