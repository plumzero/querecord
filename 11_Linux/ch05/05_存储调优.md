
这里简单记录一些存储优化的思路。目的是:
1. 优化存储，加快处理速度
2. 根据每台机器上的内存，合理估计订单量
3. 根据要扩展的订单量，合理订购内存

### 大块内存去指针

大块内存如订单列表、成交列表等，采用 vector 进行存储。假设每台机器上 100w 个订单，则存储这些指针需要 8M 。

当前 vector 的存储对象为指针，其真正的内存对象在别处，如果 vector 直接存储原内存对象，预想在效率上应该会有一定的提升。对此做了一个独立对比测试:

存储原对象:
```cpp
  using Type = TradeOrder;
  sz = 2000000;
  std::vector<Type> vec;
  vec.reserve(sz * sizeof(Type));

  for (size_t i = 0; i < sz; i++) {
      vec.emplace_back(Type());
  }
  // 随机取出修改 409600 次
```
存储原对象指针:
```cpp
  using Type = TradeOrder;
  sz = 2000000;
  std::vector<Ptr> vec;
  vec.reserve(sz * sizeof(Ptr));

  for (size_t i = 0; i < sz; i++) {
      vec.emplace_back(new Type());
  }
  // 随机取出修改 409600 次
```
不过真实测试下来的情况时，二者之间并没有太大差距，在秒级别上是相等的。这和预想有些不一致。

这里给出一个参考解释: 在上面的对比测试中，分配动态内存是在一个 for 循环中连续进行的，分配场景比较单一，其分配的内存很可能是局部连续的，纵使是随机取出修改，但高速缓存的命令率依然很高。也就是说，CPU 与 cache 的交互多一些，与物理内存的交互相比少一此，导致两次测试结果无明显差别。

而真实的环境中则比较复杂，所以上面的测试可以作为一个参考，但并不能作为最终的结果。

> 可以尝试应用正态分布对整个环境进行系统测试，以作前后对比。

### 使用大页内存

物理内存是按页进行划分的，缺省为 4k。

这里假设 vector 存储原对象(订单)，为 vector 自定义一个分配器，该分配器从大页中获取内存，大页尺寸为 2M(这也是系统常规定义的大页尺寸)。

但是实际测试下来，效果并没有提升。

这里顺便也对 github 上的一些分配器拿来进行了一下测试，效率也没有多少差别。说明 vector 的默认分配器已经足够合适。

另外，关于大页内存学习和测试记录如下:
- [简单使用](hugepage_简单使用.md)
- [数组测试](hugepage_数组测试.md)
- [结构测试](hugepage_结构测试.md)

### 内存对齐

针对一些结构体(如 TscStruct/MktStruct/OrderStruct)而言，主要包括两个方面:
- 整个结构体的内存对齐，也就是说，结构体和长度应该是 8 的倍数
- 针对结构体内部的热点字段进行内存对齐，也就是说，某热点字段地址偏移结构体地址长度应该是 8 的倍数

通过这种方式，尝试进行存储读写的提升。

### 局部存储

更细粒度级别优化，全局存储(多线程使用)靠近物理内存，局部存储靠近CPU。
