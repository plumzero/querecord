
参考
* [部署一个健壮的apache-airflow调度系统](https://www.cnblogs.com/xiongnanbin/p/11836049.html)
* [Celery Executor](https://airflow.apache.org/docs/apache-airflow/stable/executor/celery.html)

在这之前进行的都是单节点的内容，现在配置多节点部署。

多节点涉及到执行器(Executor)，airflow 缺省使用 SequentialExecutor 作为执行器，但它一次最多只能执行一个任务，且在运行任务时会阻塞调度器的工作。因此不适合用作生产环境。

在单台机器上，可以使用 `LocalExecutor` 作为执行器，对于多节点集群中，可以使用 Kubernetes executor 或者 Celery executor 作为执行器。

这里选择执行器 `CeleryExecutor` 。

> 采用分布式集群部署时，必须确保每个节点下的配置和 DAG 文件完全一致。因为节点之间的交流只会传递简单的字符串命令，而不会传递配置或 DAG 文件。
> 为了保证各节点配置和 DAG 文件的一致性，你可以通过定时任务 cronjob 或者其他方式来将 DAG 文件和配置定时(比如每隔 5 分钟)同步到每个节点。

这里主要对执行器 CeleryExecutor 进行说明。


### 配置 CeleryExecutor

CeleryExecutor 可以水平扩展 worker 进程。为了实现这个目标，可以为 Celery 设置一个后端(如 RabbitMQ 或 Redis)。修改配置文件中 airflow.cfg 的 `CeleryExecutor` 项，使其关联到一个后端

主要是对 airflow 的配置文件 `airflow.cfg` 进行修改。

将执行器 executor 更改为 `CeleryExecutor`:
```cfg
    [core]
    executor = CeleryExecutor
```

设置 broker，这里是 redis:
```cfg
    [celery]
    broker_url = redis://:redispassword@192.168.2.113:6379/0
```

这里选择 PostgreSQL 作为存储后端，修改配置如下:
```cfg
    [celery]
    result_backend = db+postgresql+psycopg2://airflower:yourpassword@192.168.2.113:5432/celery
```

### 启动守护进程

1.启动 webserver 进程

它是一个守护进程，用于接收 HTTP 请求:
```sh
    airflow$ airflow webserver -p 8080
```
webserver 守护进程使用 gunicorn 服务器处理并发请求，通过 airflow.cfg 文件中的 `workers` 的值来控制处理并发请求的进程数。默认启动 4 个 gunicorn worker 进程处理 web 请求。

2.启动 scheduler 进程

它也是一个守护进程，用于周期性地轮询任务的调度计划，以确定是否触发任务执行。
```sh
    airflow$ airflow scheduler
```

3.启动 worker 进程

worker 也是一个守护进程，它启动 1 个或多个 Celery 的任务队列，负责执行具体的 DAG 任务。

当配置 airflow.cfg 的 `executors` 设置为 `CeleryExecutor` 时才需要开启 worker 守护进程。
```sh
    airflow$ airflow celery worker -c 2
```
`-c` 指定 worker 数量，默认为 1 。

4.启动 flower 进程

也是一个守护进程，用于监控 celery 消息队列。
```sh
    airflow$ airflow celery flower
```
该进程启动后，可以在 web 页面中进行访问监控，默认端口为 5555 。

如果需要在后台启动，那就在每个启动命令后面加上参数 `-D`。

### 守护进程的运行方式

airflow 的守护进程彼此之间是独立的，他们并不相互依赖，也不相互感知。每个守护进程在运行时只处理分配到自己身上的任务，他们在一起运行时，提供了 airflow 的全部功能。

调度器 scheduler 会间隔性的去轮询元数据库(Metastore)已注册的 DAG(有向无环图，可理解为作业流)是否需要被执行。如果一个具体的 DAG 根据其调度计划需要被执行，scheduler 守护进程就会先在元数据库创建一个 DagRun 的实例，并触发 DAG 内部的具体 task(任务，可以这样理解: DAG 包含一个或多个task)，触发其实并不是真正的去执行任务，而是推送 task 消息至消息队列(即 broker)中，每一个 task 消息都包含此 task 的 DAG ID，task ID，及具体需要被执行的函数。如果 task 是要执行 bash 脚本，那么 task 消息还会包含 bash 脚本的代码。

用户可能在 webserver 上来控制 DAG，比如手动触发一个 DAG 去执行。当用户这样做的时候，一个 DagRun 的实例将在元数据库被创建。

worker 守护进程将会监听消息队列，如果有消息就从消息队列中取出消息，当取出任务消息时，它会更新元数据中的 DagRun 实例的状态为正在运行，并尝试执行 DAG 中的 task，如果 DAG 执行成功，则更新 DagRun 实例的状态为成功，否则更新状态为失败。

### 多节点部署

在进行多节点部署的说明之前，我们再来默念前面提到的一段话，那就是: <strong>airflow 的守护进程彼此之间是独立的，他们并不相互依赖，也不相互感知。每个守护进程在运行时只处理分配到自己身上的任务，他们在一起运行时，提供了 airflow 的全部功能。</strong>

好了，现在我们可以这样理解: airflow 的多节点部署其实就是 worker 进程在多台机器的运行，而 webserver 和 scheduler 进程在集群只要存在一个就行了，flower 进程也一样。

当然，你可以扩展 webserver 守护进程，以防止太多的 HTTP 请求出现在一台机器上，或者想为 webserver 的服务提供更高的可用性。

不过，每次只能运行一个 scheduler 守护进程。如果你有多个 scheduler 运行，那么就有可能一个任务被执行多次。这可能会导致您的工作流因重复运行而出现一些问题。

比如，为了实现多节点部署，现在你可以将 webserver、scheduler 和 flower 在 A 机器(作为 master)上启动，而在 B、C、D...(作为 worker)机器上启动 worker 进程。

多节点部署好处如下:
* 高可用: 如果一个 worker 节点崩溃或离线时，集群仍可以被控制，其他 worker 节点的任务仍会被执行。
* 分布式处理: 如果你的工作流中有一些内存密集型的任务，任务最好是分布在多台机器上运行以便得到更快的执行。
* 水平扩展 worker 节点: 你可以通过向集群中添加更多 worker 节点来水平地扩展集群，并使这些新节点指向同一个元数据库，从而分发处理过程。由于 worker 不需要在任何守护进程注册即可执行任务，因此worker 节点可以在不停机，不重启服务下的情况进行扩展，也就是说可以随时扩展。
* 垂直扩展 worker 节点: 你可以通过增加单个 worker 节点的守护进程数来垂直扩展集群。可以通过修改配置文件 airflow.cfg 中 `worker_concurrency` 的值来实现，或者在启动 worker 进程时通过参数 `-c` 指定。

### 多节点部署注意

1.确保集群中只有一个 scheduler 进程

上面已经说过。

2.确保所有机器使用同一份配置文件

这个没什么好说的。

3.确保所有机器使用同一份任务代码，也就是 DAG 文件

在整个调度系统中，节点之间的传递介质是消息，而消息的本质内容是执行脚本的命令，也就是说，worker 节点的 DAG 文件必须和 master 节点的 DAG 文件保持一致，不然任务的执行会出问题。
