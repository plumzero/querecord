
### 用于测试的 DAG 未消除

描述:
在配置中将 `load_examples` 设置为 `False` 后，重启 webserver，在页面中仍存在用于测试的 DAG 。

解决:
在 webserver 启动之前重置一下数据库:
```sh
    airflow$ airflow db reset
```


### 新添加的 DAG 未在 web 页面上显示

描述:
将 DAG 文件放置到 `dags_folder` 指定目录下后，刷新 web 页面，并没有显示出来。

解决:
不能总是 reset 数据库啊，把 `scheduler` 进程启动起来就好了。
```sh
    airflow$ airflow scheduler
```


### 启动 `scheduler` 进程时报错

报错如下:
```sh
    psycopg2.errors.InsufficientPrivilege: permission denied for table celery_taskmeta
```

以数据库超级用户 postgres 进入 `celery` 库，为其赋予权限:
```sh
    celery=# GRANT ALL PRIVILEGES ON TABLE celery_taskmeta TO airflower;
    GRANT
```
这个错误一般是不会发生的，除非你用的不是 airflower 用户初始化的数据库。


### 启动 `worker` 进程时报错

情况一:

报错如下:
```sh
    psycopg2.errors.InsufficientPrivilege: permission denied for sequence task_id_sequence
```

以数据库超级用户 postgres 进入 `celery` 库，为其赋予权限:
```sh
    celery=# GRANT ALL PRIVILEGES ON SEQUENCE task_id_sequence TO airflower;
    GRANT
```
这个错误一般是不会发生的，除非你用的不是 airflower 用户初始化的数据库。

情况二:

```txt
    Traceback (most recent call last):
    File "/home/airflow/anaconda3/bin/airflow", line 8, in <module>
        sys.exit(main())
    File "/home/airflow/anaconda3/lib/python3.8/site-packages/airflow/__main__.py", line 40, in main
        args.func(args)
    File "/home/airflow/anaconda3/lib/python3.8/site-packages/airflow/cli/cli_parser.py", line 47, in command
        func = import_string(import_path)
    File "/home/airflow/anaconda3/lib/python3.8/site-packages/airflow/utils/module_loading.py", line 32, in import_string
        module = import_module(module_path)
    File "/home/airflow/anaconda3/lib/python3.8/importlib/__init__.py", line 127, in import_module
        return _bootstrap._gcd_import(name[level:], package, level)
    File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
    File "<frozen importlib._bootstrap>", line 991, in _find_and_load
    File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
    File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
    File "<frozen importlib._bootstrap_external>", line 783, in exec_module
    File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
    File "/home/airflow/anaconda3/lib/python3.8/site-packages/airflow/cli/commands/celery_command.py", line 29, in <module>
        from flower.command import FlowerCommand
    ImportError: cannot import name 'FlowerCommand' from 'flower.command' (/home/airflow/anaconda3/lib/python3.8/site-packages/flower/command.py)
```

可能是 `flower` 命令没有安装成功的缘故，重新安装一下:
```sh
    airflow$ pip install flower redis redis celery==4.4.7
```


### 替换或修改 DAG 文件

删除、替换或修改 DAG 文件时，最好不要立即删除 `dags_folder` 目录下的文件，而应该采取这样的步骤:
1. 在 web 页面上点击垃圾桶图标(Delete DAG)进行删除
2. 之后再对 `dags_folder` 下的相应文件进行删除、替换或修改

`scheduler` 进程会定时轮询 `dags_folder` 目录，所以一段时间后，刷新页面就可以看到又显示到页面上了。

`scheduler` 的轮询时间可以通过 airflow.cfg 中的 `scheduler.dag_dir_list_interval` 配置项进行修改，默认为 300 秒。

### 执行 DAG 文件中任务一直处理 running 状态

是不是没有启动 `worker` 进程~


### 数据库初始化时报错
 
报错内容如下:
```sh
    ERROR [flask_caching.backends.filesystemcache] set key '__wz_cache_count' -> [Errno 1] Operation not permitted: '/tmp/tmp2zjpe88l.__wz_cache' -> '/tmp/2029240f6d1128be89ddc32729463129'
```

产生场景: 在同一台机器上配置两套 Airflow 环境，在启动第二套时报错。

解决: 启动第一套后，删除 `/tmp/2029240f6d1128be89ddc32729463129` 文件。


### 修改时区问题

问题描述见这里: [Airflow修改时区问题](https://www.codenong.com/js072cbe35bc89/)

参考解决办法在这里: [Airflow1.10.4介绍与安装](https://www.cnblogs.com/woshimrf/p/airflow-install-with-docker.html)

集群或者不同用户下可能需要一个一个的修改，比较麻烦。

个人未作尝试，觉得没有必要。
... 或者以后会有更好的办法。

### 后台启动 airflow 进程失败

使用其他机器上的数据库，修改 airflow.cfg 相关配置项，之后尝试前台启动执行 `airflow webserver` 命令，没什么问题。但是添加参数 `-D` 再执行，后台并没有相关进程在运行。

解决办法: 进入 `$AIRFLOW_HOME` 目录下，将一些垃圾文件删除。垃圾文件具体是指除了 airflow.cfg、logs、dags、webserver_config.py 之外的一些 airflow 产生的一些进程、输出、日志等文件。
